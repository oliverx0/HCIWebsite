<!DOCTYPE HTML>
<!--
	Astral by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Pallette! The tongue-computer interface @ Cornell Tech</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="css/ie/html5shiv.js"></script><![endif]-->
		<script src="js/jquery.min.js"></script>
		<script src="js/skel.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-desktop.css" />
			<link rel="stylesheet" href="css/style-noscript.css" />
		</noscript>

		<style type="text/css">

			h3{

				margin-top: 1.5em;
  				margin-bottom: 0.8em;
  				color: #818181;
  				font-size: 35px;
			}

			h4{

				margin-top: 1.1em;
  				margin-bottom: 0.8em;
  				color: #64636e;
  				font-size: 27px;
  				text-decoration: underline;
  				opacity: 0.6;
			}

			figure{
				width: 650px;
				margin: auto;
				margin-bottom: 1.5em;
			}

			figcaption{

				text-align: center;
			}

			.image_pallette
			{
				width: 650px;
				height: auto;
			}

		</style>
		<!--[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]-->
	</head>
	<body>

		<!-- Wrapper-->
			<div id="wrapper">
				
				<!-- Nav -->
					<nav id="nav">
						<a href="#me" class="icon fa-home active"><span>Home</span></a>
						<a href="#work" class="icon fa-wheelchair"><span>Pallette</span></a>
						<a href="#docs" class="icon fa-folder"><span>Documents</span></a>
						<a href="#contact" class="icon fa-envelope"><span>Contact</span></a>
					</nav>

				<!-- Main -->
					<div id="main">
						
						<!-- Me -->
							<article id="me" class="panel">

								<header>
									<div class="team">
										<div class="team_member">
											<div class="img_team">
												<img src="https://pbs.twimg.com/profile_images/1775096406/Foto.JPG">
											</div>
											<p>Oliver Hoffman</p>
										</div>

										<div class="team_member">
											<div class="img_team">
												<img src="http://challengepost-s3-challengepost.netdna-ssl.com/photos/production/user_photos/000/189/576/datas/profile.jpg">
											</div>
											<p>Dan Levine</p>
										</div>

										<div class="team_member">
											<div class="img_team">
												<img src="http://challengepost-s3-challengepost.netdna-ssl.com/photos/production/user_photos/000/246/717/datas/profile.jpg">
											</div>
											<p>Shawn Bramson</p>
										</div>

									</div>
									<h1>Pallette</h1>
									<p>The tongue-computer interface</p>
								</header>
								<a href="#work" class="jumplink pic">
									<span class="arrow icon fa-chevron-right"><span>See my work</span></span>
									<img src="images/me2.jpg" alt="Pallette" />
								</a>
							</article>

						<!-- Work --> 
							<article id="work" class="panel">
								<header>
									<h2>Pallette - The Tongue-Computer Interface!</h2>
								</header>
								<p>
									Currently quadriplegics do not have a mobile, discreet method of finely controlling the technology used in their daily lives. We envision a tongue interface capable of controlling technology to enable more independent living. The tongue is one of the most sensitive and versatile muscles in the body, it is also concealed within the mouth. Though previous attempts of using the tongue as an interface for technology exist, none of them have succeeded in achieving a comfortable and lasting experience for the users while enabling control of multiple technologies.
								</p>
								<p>
									We have created a tongue interface for mouse control with the long term goal of enabling greater independence through control of technology. Our base design is based off of the concept of the mouse. By taking a universal input device normally used by the hand and configuring it for the tongue, we enable SCI patients to use any technology normally facilitated by conventional mouse control. Our device is held in place by a retainer (our prototype, by a mouthguard), providing 2 buttons for commands and a trackpoint for navigation and direction. It has been contoured very carefully to fit the upper dome of the mouth and has established comfortable, simple control in testing.
								</p>

								<iframe style="display: block; margin: auto; margin-bottom: 1.5em;" width="420" height="315" src="https://www.youtube.com/embed/ldZwopL6KFE" frameborder="0" allowfullscreen></iframe>

								<p>
									Pallete is still a work in progress, but we envision the final product to be something like the following images:
								</p>

								<figure>
									<img class="image_pallette" src="images/joystick.png" alt="Pallette Design">
									<figcaption>Sketch for joystick with buttons</figcaption>
								</figure>

								<figure>
									<img class="image_pallette" src="images/touchpad.png" alt="Pallette Design">
									<figcaption>Sketch for touchpad with buttons</figcaption>
								</figure>

								<h3>Pallette's Design</h3>

								<p>
									The final prototype possesses the functions of a mouse, except that instead of operating it with hands and limbs it sits on the roof of the mouth and is operated with the tongue. The design incorporates three elements. Two clickable buttons are mounted as large-area buttons on the left and right sides of the interface, and a pressure-sensitive trackpoint nub is mounted in between. The pressure sensitive nub can be pushed in all directions with a continuous spectrum of movement spanning a 2-D plane. (For reference, this “trackpoint nub” is the same as the red blip mouse found on most IBM thinkpad laptops). This nub controls a mouse cursor. The size and texture of the button clicks have been made tactile through lever motion of plastic and wide button caps. The trackpoint tip is concave, enabling the tip of the tongue to grip and better direct the cursor.

								</p>

								<p>
									We also incorporated trackpoint sensitivity sensitivity within the source code allowing us to easily increase or decrease the sensitivity as desired. In fact, we can even scale sensitivity for a specific axis, X or Y. We found this helped greatly given the strength and precision of a tongue differs from person to person. Also the agility of the tongue is different from left to right contrasted with front to back.
								</p>
								<figure>
									<img class="image_pallette" src="images/pallete-design.png" alt="Pallette Design">
									<figcaption>Pallette's current design</figcaption>
								</figure>

								<h3>Pallette's Previous Prototypes</h3>

								<h4>Initial Low-Fi Prototypes</h4>

								<p>
									To initally prototype our tongue-controlled interface, we created two sets of prototypes; one set to asses the haptic function of button pressing using a modified calculator, and another to asses the form of the interface inside the mouth. Both prototype sets were meant to rest against the top of the mouth and interfaced by the tongue from below. 

								</p>

								<p>
									The first prototype consisted of a $4 <strong>calculator</strong>, which was used to test the ability of users to perform operations with their tongue. The idea behind it was to ask users to press different buttons and see based on the results of the scree if their input was correct. This would give us an idea of how easy it is to control a button set inside the mouth. 

								</p>

								<figure>
									<img class="image_pallette" src="images/calculator.png" alt="Calculator Prototypes">
									<figcaption>Versions 1 and 2 of the calculator-based prototype</figcaption>
								</figure>

								<p>
									Version 1 of the calculator-based protoype was constructed from a full portable calculator. The prototype was wrapped in plastic, with the button portion being placed in the person’s mouth. The designer asked the person to press certain buttons or perform certain operations and the person attempted to do so. Participants complained about the large size; some people could barely fit the keypad into their mouth. Furthermore while the buttons were easy to push by hand, they were difficult to push by the tongue. Buttons towards the back of the keypad were hardest to push, as participants found it difficult to reach towards the back of their mouth. Buttons were easiest to press in immediate circumference around the center of the keypad. 

								</p>

								<p>
									Version 2 attempted to address these concerns by reducing the size of the keypad and reducing tactile load required to press the buttons. The the keypad was folded and clamped with tape, and the buttons were replaced with conductive metal slats. These slats enabled a button press with a gentle tap of the tongue.
								</p>

								<p>
									The second protype consisted of <strong>foam forms</strong>, which were used to address the sensation of a user having something in his mouth designed to be used for longer periods of time. This would give us an initial impression of what it might feel like to use our tongue- interface technology. It also gave us, the designers, an impression of how complicated it might be to fit the buttons to be handled by the user within the constraints of the shape of the mouth without being uncomfortable.
								</p>

								<figure>
									<img class="image_pallette" style="width: 400px;
  margin: auto;
  display: block;" src="images/foam.png" alt="Foam Prototypes">
									<figcaption>Versions 1 - 3 of the foam-based prototype</figcaption>
								</figure>

								<p>
									Version 1 attempted to create a thin, less defined form as a staring base to understand how big we could make the form within the confines of the mouth. This first guess proved to be too big to reasonably fit in the mouth. When used it looked like a blue tongue sticking out of the mouth.
								</p>

								<p>
									Version 2 reduced the size and profile of version 1 according to one of our participants feelings on sizing. After an initial trial, the form was curved to better fit the curvature of the mouth. This form fit with adequate space, and the participant felt like they were able to comfortably reach the majority of exposed real estate. The two most prominent complaints were 1) the prototype was not attached to the top of the mouth and would sometimes float around and 2) it did not include an identifiable buttons and therefore left the interface mapping up to the imagination.

								</p>

								<p>		
									Using the form factor of version 2, version 3 was created with a button and control layout. It has not been tested with participants yet, although a small test by one of the designers yielded that the buttons were recognizable by the tongue quite well despite their small size, and that some of this interface should be streamlined with less number of elements and more distinct elements to individual touch.

								</p>

								<h4>Mid-Fi Prototypes</h4>

								<p>
									Based on the users’ feedback during the previous prototype versions, we kept testing different materials to get a better understanding of what might be comfortable for the user. In that sense, we tried materials that varied from chocolate and cheese to plastic and foam. This helped us understand different textures that might be familiar for the user when using our product. We then proceeded to address the problem of operating with our previous prototype that used a calculator screen to indicate success of operations. This time around we built a more robust prototype that: a) had a shape that allowed for easy insertion in the mouth, and b) was able to perform the operations of turning lights on and off with 2 different buttons.

								</p>

								<figure>
									<img class="image_pallette" src="images/midfi_design.png" alt="Mid-Fi Prototype Design">
									<figcaption>Design of the Mid-Fi Protype</figcaption>
								</figure>

								<p>
									The tools used for building our prototype consisted of: Arduino (to make all the connections to the buttons and the lights and program it so that on a button push the lights would turn on), LED lights, Pushable buttons (that would activate the LED lights), and Plastic which would cover the buttons and work as our device to be put inside the mouth. The shape of this plastic cover was modified through heat. Tape was sued to keep everything together, cables were used to connect the buttons to LEDs, and plastic bags were used to allow for multiple uses of our prototypes by different people.

								</p>

								<p>
									Previous versions of the material used in our prototype included stuffs, which were helpful to address what the shape of the device should be, but the feeling was not very much liked during the heuristic evaluation. Because of this, we decided to then go with plastic, which has so far been very successful.

								</p>

								<figure>
									<img class="image_pallette" src="images/midfi.png" alt="Mid-Fi Prototype">
									<figcaption>Mid-Fi Protype</figcaption>
								</figure>

								<h4>Hi-Fi Prototypes and Field User Tests</h4>

								<p>
									After the previous iterations, we finally got to our Hi-Fi prototype. This prototype acts as an interface as in the form of mouse to a computer and is encased in a vacuum formed housing that sits in the concave dome behind the teeth of the upper jaw. Mouse interfacing was achieved through the rewiring of mouse components. The interface is exposed to the tongue as two buttons - “Left” and “Right”. These two buttons take up the entirety of the exposed interface to aid in control by the tongue. With this prototype we seek to test users’ control and comfort through a sequence of computer interfacing tasks. In designing a tongue interface we wish to make sure that the device comfortably fits in the user’s mouth and the users have fine enough control to achieve their desired tasks without frustration. 

								</p>

								<figure>
									<img class="image_pallette" src="images/hifi.png" alt="Hi-Fi Prototype">
									<figcaption>Hi-Fi Protype</figcaption>
								</figure>

								<p>
									We then proceeded to test the protoype in the real world based on 3 tasks of varying motor difficulty users would need to perform.  
								</p>

								<p>
									The first <strong>simple task</strong> consisted of giving a screen which randomly indicates what button to press and the user pressing those buttons. A counter of the right and wrong inputs is then recorded. This task allows to test comfort and control.  
								</p>

								<figure>
									<img class="image_pallette" style="width: 400px;
  margin: auto;
  display: block;"  src="images/task1.png" alt="Simple Task">
									<figcaption>Screen showing the simple task</figcaption>
								</figure>

								<p>
									The second <strong>moderate task</strong> consisted of giving a users a pdf document of several pages long, and having them scroll up and down by clicking on the buttons. The rationale behind this task was to gain a qualitative impression of the feeling of the device in a common task users al already used to doing in another way. The scrolling of documents was very simple for us to do, since all that was need was to map the up and down arrow keys to the left and right clicks. After performing the task, users were asked for a general impression of the task, if they found any difficulties, if they felt in control all the time, and if they had any other feedback to provide.
								</p>

								<p>
									The third <strong>complex task</strong> consisted of the user playing a video game using only the tongue-interface. The rationale behind this task was to gain a better understanding of the amount of control a user can have when using the tongue interface in complex, dynamic environments. Because of this, users were asked to play a simple video game which only required them to click every time they wanted a block to jump and evade obstacles. We measure the score of the game session as the quantitive variable. Users were asked to play the video game 3 times, and the highest and lowest scores were recorded.
								</p>

								<p>
									After running the tasks with the different participants of our study, we arrived to the conclusion that the tasks performed were all quite simple for users to do. This gave us great insight into understanding what we were doing right and wrong.
								</p>

								<p>
									Based on the results received, we were then ready to take our prototype to the next level by incorporating a joystick-like functionality in order to actually be able to move the mouse around. This would give us an even better impression of the tasks that the final users were expected to perform. Moreover, the use of plastic bags to cover the prototype was well- received among users, meaning that in future scenarios we would continue using it.
								</p>

								<h4>Building the final version</h4>

								<p>
									After all the lessons learned, we decided it was time to incorporate the mouse controlling functionality into our device. 
									Based on the feedback we received from the previous high fidelity prototype we added the trackpoint for more fine control and incorporated all elements into a fixed mouthguard retainer. This addressed two major concerns of not having the device fixed in place and not being able to discern the left and right side. The presence of the trackpoint further provides subtle intuition of the divide from left to right.
								</p>

								<p>
									Additionally, the tactile feel of the buttons significantly improved over past versions; the new version incorporated the mechanics of a keyboard in order to increase the accuracy of button presses. Finally we designed the wire coming out the side of the apparatus and bundled it in a thin beige tube to be more subtle.
								</p>

								<p>
									In order to do add the trackpoint, we used ripped out several old IBM laptops to take the trackpoint from their keyboards. These trackpoints were attached to small boards that allowed us to connect the trackpoint to an Arduino Micro. 
								</p>

								<figure>
									<img class="image_pallette" style="width: 400px;
  margin: auto;
  display: block;"  src="images/trackpoint_back.png" alt="TrackPoint Back">
									<figcaption>Back of the TrackPoint board with connection pins</figcaption>
								</figure>

								<figure>
									<img class="image_pallette" style="width: 400px;
  margin: auto;
  display: block;"  src="images/trackpoint2.png" alt="TrackPoint Arduino">
									<figcaption>Connecting the TrackPoint and buttons to the Arduino</figcaption>
								</figure>

								<p>
									After being able to move the cursor of the mouse with the TrackPoint connected to the Arduino and adding 2 buttons that would act as a left and right click, it was time incorporate it into the device. In order to do this, we bought a $13 mouthguard that would help fit the device into the mouth and built a small form to house the trackpoint and the buttons. It is worth noting that to determine the right size of the device, we used a mouth mold.
								</p>

								<figure>
									<img class="image_pallette" style="width: 400px;
  margin: auto;
  display: block;"  src="images/mouthguard.png" alt="Mouthguard">
									<figcaption>Mouthguard to hold the device</figcaption>
								</figure>

								<figure>
									<img class="image_pallette" style="width: 400px;
  margin: auto;
  display: block;"  src="images/housing.png" alt="Mold">
									<figcaption>Fitting the device in the mold</figcaption>
								</figure>

								<p>
									The last step consisted on adding plastic covers to the device buttons, and it was ready go!
								</p>

								<figure>
									<img class="image_pallette"  style="width: 400px;
  margin: auto;
  display: block;"  src="images/final.png" alt="Final">
									<figcaption>Final result</figcaption>
								</figure>

								<p>
									This final prototype possesses the functions of a mouse, except that instead of operating it with hands and limbs it sits on the roof of the mouth and is operated with the tongue. The design incorporates three elements. Two clickable buttons are mounted as large-area buttons on the left and right sides of the interface, and a pressure-sensitive trackpoint nub is mounted in between. The pressure sensitive nub can be pushed in all directions with a continuous spectrum of movement spanning a 2-D plane. (For reference, this “trackpoint nub” is the same as the red blip mouse found on most IBM thinkpad laptops). This nub controls a mouse cursor. The size and texture of the button clicks have been made tactile through lever motion of plastic and wide button caps. The trackpoint tip is concave, enabling the tip of the tongue to grip and better direct the cursor.
								</p>

								<p>
									We also incorporated trackpoint sensitivity sensitivity within the source code allowing us to easily increase or decrease the sensitivity as desired. In fact, we can even scale sensitivity for a specific axis, X or Y. We found this helped greatly given the strength and precision of a tongue differs from person to person. Also the agility of the tongue is different from left to right contrasted with front to back.
								</p>

								<h4>Unimplemented functionality and next steps </h4>

								<p>
									For this final prototype, we sought to include the most essential functions of moving, clicking, and holding. A few functions that require more complex combinations of these functions were left out; namely click & drag. Furthermore, functions of greater engineering complexity such as wireless communications were also omitted for sake of available time and resources.
								</p>

								<p>
									Our focus moving forward, is to both refine the basic (essential) functionalities we have imbued our interface through form and element positioning, and to develop and include the more complex functionalities we have discussed. At the moment, we are considering using macros to emulate complex actions such as click and drag. Holding down a button for a multi-second duration is intended to serve as its trigger.

								</p>

								<!-- 
								<section>
									<div class="row">
										<div class="4u">
											<a href="#" class="image fit">
												<p>Hello</p>
												<img src="images/pic01.jpg" alt="">

											</a>
										</div>
										<div class="4u">
											<a href="#" class="image fit"><img src="images/pic02.jpg" alt=""></a>
										</div>
										<div class="4u">
											<a href="#" class="image fit"><img src="images/pic03.jpg" alt=""></a>
										</div>
									</div>
									<div class="row">
										<div class="4u">
											<a href="#" class="image fit"><img src="images/pic04.jpg" alt=""></a>
										</div>
										<div class="4u">
											<a href="#" class="image fit"><img src="images/pic05.jpg" alt=""></a>
										</div>
										<div class="4u">
											<a href="#" class="image fit"><img src="images/pic06.jpg" alt=""></a>
										</div>
									</div>
									<div class="row">
										<div class="4u">
											<a href="#" class="image fit"><img src="images/pic07.jpg" alt=""></a>
										</div>
										<div class="4u">
											<a href="#" class="image fit"><img src="images/pic08.jpg" alt=""></a>
										</div>
										<div class="4u">
											<a href="#" class="image fit"><img src="images/pic09.jpg" alt=""></a>
										</div>
									</div>
									<div class="row">
										<div class="4u">
											<a href="#" class="image fit"><img src="images/pic10.jpg" alt=""></a>
										</div>
										<div class="4u">
											<a href="#" class="image fit"><img src="images/pic11.jpg" alt=""></a>
										</div>
										<div class="4u">
											<a href="#" class="image fit"><img src="images/pic12.jpg" alt=""></a>
										</div>
									</div>
								</section>
								-->
							</article>

						<!-- Documentation -->

						<article id="docs" class="panel">
								<header>
									<h2>Project Documents</h2>
								</header>
								<p>The documents with further detail about the projects execution can be found here: </p>

								<p>
									<ul style="margin-left: 30px; margin-top: -15px">
										<li><a href="pdf/HW2.pdf">Project Proposal</a></li>
										<li><a href="pdf/HW3.pdf">Contextual Interviews</a></li>
										<li><a href="pdf/HW4.pdf">Video Storyboarding</a></li>
										<li><a href="pdf/HW5.pdf">Low-Fi Prototypes and Heuristic Evaluation</a></li>
										<li><a href="pdf/HW6.pdf">Mid-Fi Prototype</a></li>
										<li><a href="pdf/HW7.pdf">Hi-Fi Prototype and Field User Test</a></li>
										<li><a href="pdf/HW8.pdf">Hi-Fi Protype 2</a></li>
										<li><a href="images/video.mp4">Final Video</a></li>
								</p>
								
							</article>
						<!-- Contact -->
							<article id="contact" class="panel">
								<header>
									<h2>Contact Us</h2>
								</header>
								<p>Interested in Pallette? Shoot us an email at <email>ojh22 [at] cornell.edu</email> and we will get back to you ASAP. Alternatively, fill out the following form: </p>

								<form action="#" method="post">
									<div>
										<div class="row">
											<div class="6u">
												<input type="text" name="name" placeholder="Name" />
											</div>
											<div class="6u">
												<input type="text" name="email" placeholder="Email" />
											</div>
										</div>
										<div class="row">
											<div class="12u">
												<input type="text" name="subject" placeholder="Subject" />
											</div>
										</div>
										<div class="row">
											<div class="12u">
												<textarea name="message" placeholder="Message" rows="8"></textarea>
											</div>
										</div>
										<div class="row">
											<div class="12u">
												<input type="submit" value="Send Message" />
											</div>
										</div>
									</div>
								</form>
							
							</article>

					</div>
		
				<!-- Footer -->
					<div id="footer">
						<ul class="copyright">
							<li>&copy; Pallette.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</div>
		
			</div>

	</body>
</html>